{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b8cbfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from decimal import *\n",
    "# generate random Gaussian values\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn,randint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09162db",
   "metadata": {},
   "source": [
    "### Calculate sorption parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa1ce56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_list = [[[0.59,0.67],[],[0.68,0.72],[0.45,0.55],[0.56,0.58],[],[]], # II\n",
    "                [[0.340,0.43],[],[0.44,0.47],[0.30,0.33],[0.20,0.29],[0.48,0.55],[0.100,0.200],[0.56,0.700],[0.71,100],[0,0.09]], #III\n",
    "                [[0.20,0.29],[0.040,0.055],[0.30,0.35],[0.40,0.50],[0,0.19],[]], # V\n",
    "                [[0.76,0.83],[],[0.40,0.75],[0.84,1.3],[1.4,3.0],[3.1,100],[]], # I\n",
    "                [[0.561,0.659],[0.27,0.33],[0.66,0.69],[0.70,0.75],[0.50,0.56],[0.34,0.49],[0.76,0.95],[0.96,100],[0,0.26]], # IV               \n",
    "                [[53,67],[],[40,52],[68,70],[0,39],[71,100],[0,30]], #T\n",
    "                [[0.22,0.26],[],[0.17,0.21],[0.27,0.30],[0.31,0.43],[0.10,0.16],[0.44,0.55]]] # S(30/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7600d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path_texts):\n",
    "    return pd.read_excel(path_texts, sheet_name=1, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "215f3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfg_converter(lines):\n",
    "    #splitting to title string and numerical data\n",
    "    title_raw = lines[:8]\n",
    "    tf_raw = lines[8:170]\n",
    "    #numerical data list forming\n",
    "    tf_list = []\n",
    "    for i in range(len(tf_raw)):\n",
    "        line = re.sub(r\"(?i)[<point time=alue=/>]\", \"\", tf_raw[i])\n",
    "        tf_str = line.replace('v',' ').replace('\"',\"\").replace(\",\",\".\").split()\n",
    "        tf_num = float(tf_str[1])\n",
    "        tf_list.append(tf_num)\n",
    "    #title string forming\n",
    "    title_str = []\n",
    "    for i in range(len(title_raw)):\n",
    "        line = re.sub(r\"(?i)[mesure<name></name>dciptiolghk=]\", \"\", title_raw[i])\n",
    "        ts=line.replace('\"',\"\").replace(\",\",\".\").replace('\\ufeff',\"\")\n",
    "        title_str.append(ts)\n",
    "    return title_str[1:], tf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54b2764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_covid_tfg(data_path):\n",
    "    tree = ET.parse(data_path)\n",
    "    root = tree.getroot()\n",
    "    tf_arr = []\n",
    "    meta_info = root.find('name').text\n",
    "    for point in root.iter('point'):\n",
    "        tf_arr.append(int(point.attrib['value']))\n",
    "        \n",
    "    return meta_info, np.array(tf_arr, dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ca9d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arr(filename):\n",
    "    file = open(filename, encoding='utf-8')\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    \n",
    "    tfg_pred = tfg_converter(lines)\n",
    "    meta_info = tfg_pred[0]\n",
    "\n",
    "    tf_arr = np.array(tfg_pred[1])\n",
    "    tf_arr = tf_arr[0] - tf_arr\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return meta_info, tf_arr\n",
    "\n",
    "def get_arr_from_covid_tfg(filename):\n",
    "    return parse_covid_tfg(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ddea23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interval membership detector\n",
    "def detect(list, x):\n",
    "    getcontext().prec = 2\n",
    "    fl = (x >= Decimal(str(list[0])))\n",
    "    fr = (x <= Decimal(str(list[1])))\n",
    "    if fl & fr:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51b5485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of active intervals\n",
    "def ind_tx(feature_intervals, fv):\n",
    "    candidates = []\n",
    "    for k in range(len(feature_intervals)):\n",
    "        ivl = feature_intervals[k]\n",
    "        if len(ivl) == 0:\n",
    "            continue\n",
    "        if detect(ivl, fv) == 1:\n",
    "            candidates.append(k)\n",
    "    if len(candidates) == 0:\n",
    "        return -1\n",
    "    # in case of nested intervals choose the smallest\n",
    "    elif len(candidates) > 1:\n",
    "        sorted_candidates = sorted([feature_intervals[k] for k in candidates], key=lambda tup: tup[1])\n",
    "        final_candidate = sorted_candidates[0]\n",
    "        return feature_intervals.index(final_candidate)\n",
    "\n",
    "    return candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45066edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(tf_arr):\n",
    "    # precision installation\n",
    "    getcontext().prec = 2\n",
    "\n",
    "    # Noise level\n",
    "    dev=2\n",
    "    # seed random number generator\n",
    "    seed(42)\n",
    "    # generate some Gaussian values\n",
    "    tf_arrN = randint(-dev,dev,size=len(tf_arr))+tf_arr    \n",
    "\n",
    "    def integral_sum(a, b):\n",
    "        dx = b - a\n",
    "        y1 = tf_arr[a]\n",
    "        y2 = tf_arr[b]\n",
    "\n",
    "        return (y1 + y2) / 2.0 * dx\n",
    "\n",
    "    def tau_l(ref, arr):\n",
    "        i=1\n",
    "        for k in range(60):\n",
    "            if arr[i] <= ref:\n",
    "                i=i+1\n",
    "            else:\n",
    "                tleft=i-1\n",
    "                return tleft\n",
    "\n",
    "    #a(40/60)\n",
    "    f1 = Decimal(str(tf_arr[40])) / Decimal(str(tf_arr[60]))\n",
    "\n",
    "    #a(30/60)\n",
    "    f2 = Decimal(tf_arr[30]) / Decimal(tf_arr[60])\n",
    "\n",
    "    #a(20/60)\n",
    "    f3 = Decimal(tf_arr[20]) / Decimal(tf_arr[60])\n",
    "\n",
    "    #a(40/70)\n",
    "    f4 = Decimal(tf_arr[40]) / Decimal(tf_arr[70])\n",
    "\n",
    "    #a(20/30)\n",
    "    f5 = Decimal(tf_arr[20]) / Decimal(tf_arr[30])\n",
    "\n",
    "    #T\n",
    "    with localcontext() as ctx:\n",
    "        ctx.rounding = ROUND_HALF_UP\n",
    "        ref = Decimal(np.amax(tf_arr)/2).to_integral_value()\n",
    "        f6 = tau_l(ref, tf_arr) * 2\n",
    "\n",
    "    #S(30)/S(60)\n",
    "    f7 = Decimal(integral_sum(4, 30)) / Decimal(integral_sum(4, 60))\n",
    "\n",
    "    return [f1, f2, f3, f4, f5, f6, f7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2f02b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_output_text(features, interval_list, kuchmagic_table):\n",
    "    text_out = []\n",
    "    intervals = []\n",
    "    text_alarm='out of intervals'\n",
    "\n",
    "    for i, f in enumerate(features):\n",
    "        #get index of interval where the value is\n",
    "        row = ind_tx(interval_list[i], f)\n",
    "        if row == -1:\n",
    "            text_out.append(text_alarm)\n",
    "        else:\n",
    "            text_out.append(kuchmagic_table.iloc[row][i+1].strip())\n",
    "        intervals.append(row)\n",
    "    return text_out, intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2849a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get meta info and final list of texts from tfg file\n",
    "# used for output of text values of parameters\n",
    "def get_text_from_tfg(data_path, interval_list, kuchmagic_table):\n",
    "    meta_info = []\n",
    "    text = []\n",
    "\n",
    "    try:\n",
    "        meta_info, tf_arr = get_arr(data_path)\n",
    "    except:\n",
    "        meta_info, tf_arr = get_arr_from_covid_tfg(data_path)\n",
    "\n",
    "    text = []\n",
    "    if tf_arr.size > 0:\n",
    "        features = calculate_features(tf_arr)\n",
    "        text, _ = collect_output_text(features, interval_list, kuchmagic_table)\n",
    "\n",
    "    return meta_info, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "670655cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a measurment is taken on the left hand, only the token with description for left hand will be added to final text\n",
    "# the same way for the right hand\n",
    "def parse_left_right(texts):\n",
    "    new_texts = []\n",
    "    for text in texts:\n",
    "        new_text = []\n",
    "        for token in text.split(\"/\"):\n",
    "            if any(i for i in['слева', 'справа', 'левая', 'правая'] if i in f) and 'слева и справа' in token:\n",
    "                continue\n",
    "            if any(i for i in['слева', 'левая'] if i in f) and \\\n",
    "               any(i for i in['справа', 'правая'] if i in token):\n",
    "                continue\n",
    "            if any(i for i in['справа', 'правая'] if i in f) and \\\n",
    "               any(i for i in['слева', 'левая'] if i  in token):\n",
    "                continue\n",
    "            new_text.append(token)\n",
    "        new_texts.append(\"/\".join(new_text))\n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f8e5f",
   "metadata": {},
   "source": [
    "### Calculate health index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff43f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_index_interval = [[[89.5, 100], [80.5, 89.4], [70.0, 80.4], [59.5, 69.9], [54.5, 59.4], [49.5, 54.4], [29.5, 49.4], [10, 29.4]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0cbab351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_health_index(path_texts):\n",
    "    return pd.read_excel(path_texts, sheet_name=2, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6edff683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final list of texts and corresponding intervals \n",
    "# used for health index calculation\n",
    "def get_features_and_intervals(filename, interval_list, kuchmagic_table):\n",
    "    text = []\n",
    "    tf_arr = []\n",
    "    meta_info = []\n",
    "\n",
    "    try:\n",
    "        meta_info, tf_arr = get_arr(filename)\n",
    "    except:\n",
    "        meta_info, tf_arr = get_arr_from_covid_tfg(filename)\n",
    "\n",
    "    text = []\n",
    "    if tf_arr.size > 0:\n",
    "        features = calculate_features(tf_arr)\n",
    "        text, intervals = collect_output_text(features, interval_list, kuchmagic_table)\n",
    "    \n",
    "    return features, intervals, tf_arr, meta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca9bee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_health_index(filename, interval_list):\n",
    "\n",
    "    min_sp = 6.9\n",
    "    max_sp = 20.2\n",
    "\n",
    "    factor_map = [[1, 1, 1.5, 1.5, 2, 2.5, 3],\n",
    "                 [1, 1, 1.5, 1.5, 2, 2, 2.5, 2.5, 2.5, 3],\n",
    "                 [1, 1, 1.5, 2, 3, 3],\n",
    "                 [1, 1, 1.5, 1.5, 2, 2.5, 3],\n",
    "                 [1, 1, 1.5, 1.5, 1.5, 2, 2, 2.5, 3],\n",
    "                 [1, 1, 1.5, 2, 2, 2.5, 3],\n",
    "                 [1, 1, 1.5, 1.5, 2, 2.5, 2.5]]\n",
    "\n",
    "    features, intervals, tf_arr, meta_info = get_features_and_intervals(filename, interval_list, data)\n",
    "\n",
    "    i0, i1, i2, i3, i4, i5, i6 = intervals\n",
    "\n",
    "    SP = (factor_map[0][i0]*1) + \\\n",
    "         (factor_map[1][i1]*1) + \\\n",
    "         (factor_map[2][i2]*1) + \\\n",
    "         (factor_map[3][i3]*0.9) + \\\n",
    "         (factor_map[4][i4]*1) + \\\n",
    "         (factor_map[5][i5]*1.0) + \\\n",
    "         (factor_map[6][i6]*1)\n",
    "    \n",
    "    norm_result = (SP - min_sp) / (max_sp - min_sp)\n",
    "\n",
    "    health_index = (1 - norm_result) * 100\n",
    "    with localcontext() as ctx:\n",
    "        ctx.prec = 3\n",
    "        health_index = Decimal(health_index) * Decimal(1.0)\n",
    "\n",
    "    return health_index, tf_arr, meta_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf455c3",
   "metadata": {},
   "source": [
    "### Подключение к серверу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e43976f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install anvil-uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d9ad729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server\n",
    "import anvil.media\n",
    "import anvil.mpl_util\n",
    "anvil.server.connect(\"YLCFGEBMNC4EME322FFSBF5V-AMCZWDEPAXOA6IYT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c788d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('https://raw.githubusercontent.com/BogoroditskayaEkaterina/electro-nose/main/kuch_magic.xlsx')\n",
    "health_data = read_data_health_index('https://raw.githubusercontent.com/BogoroditskayaEkaterina/electro-nose/main/kuch_magic.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7147e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def make_plot(tf_arr):\n",
    "    x = list(range(0, len(tf_arr)))\n",
    "    y = tf_arr\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10,5), dpi=80)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.plot(x, y)\n",
    "    return anvil.mpl_util.plot_image()\n",
    "\n",
    "@anvil.server.callable\n",
    "def get_health_index(filename):\n",
    "    with anvil.media.TempFile(filename) as filename:\n",
    "        health_indices, tf_arr, meta_info = calculate_health_index(filename, interval_list)\n",
    "        \n",
    "        temp = []\n",
    "        for i in tf_arr:\n",
    "            temp.append(float(i))\n",
    "            \n",
    "    return(meta_info, float(health_indices), temp, collect_output_text([health_indices], health_index_interval, health_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
